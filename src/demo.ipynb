{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reddit import MyRedditAPI\n",
    "from processing import EntityRecognition, clean_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Create an instance of the MyRedditAPI Class\n",
    "- Enter your own client_id, secret_key, username, and password\n",
    "    - To create the Client ID and Secret Key: https://www.reddit.com/prefs/apps\n",
    "- For source code -> src.reddit.my_reddit_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = MyRedditAPI(\n",
    "    client_id=os.getenv(\"CLIENT_ID\"),  # API Client\n",
    "    secret_key=os.getenv(\"SECRET\"),    # API Secret\n",
    "    username=os.getenv(\"USERNAME\"),    # Reddit Username\n",
    "    password=os.getenv(\"PASSWORD\"),    # Reddit Account Password\n",
    "    user_agent='MyApiTest'             # Can be anything\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Send a request for data\n",
    "- Note that it is only possible to retrieve the number of posts that are available in reddit's \"main search\". For example, if you search anything on reddit, the maximum number of posts that will be returned is ~250. So, even if the limit is set higher than that, it will not return more than what is available to be searched in the application.\n",
    "- Defult behavior is to search all subreddits, here are some others to try:\n",
    "    - subreddit=\"ukraine\"\n",
    "    - subreddit=\"RussiaUkraineWar2022\"\n",
    "    - subreddit=\"UkraineConflict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wagner_df = session.search_posts(\n",
    "    query='Wagner Group',\n",
    "    sort='new',\n",
    "    subreddit='all',\n",
    "    limit=300\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wagner_df = clean_text(wagner_df, columns=['title', 'selftext'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Named Entity Recognition to extract locations, organizations, and people from the title (or selftext if desired)\n",
    "- Note: may need to download the en_core_web_sm spacy model: python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wagner_ner = EntityRecognition(wagner_df, 'title')\n",
    "wagner_df['locations'] = wagner_ner.get_gpe()\n",
    "wagner_df['organizations'] = wagner_ner.get_org()\n",
    "wagner_df['people'] = wagner_ner.get_person()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wagner_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8294b3418db4efbb7fadcd0975fa2e1c44e142e2fb8fc4b3a80a3f764e10ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
